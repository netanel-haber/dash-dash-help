<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>dash-dash-help</title>
  <link rel="icon" href="favicon.svg" type="image/svg+xml">
  <style>
    body { font-family: 'SF Mono', 'Monaco', 'Consolas', 'Courier New', monospace; max-width: 900px; margin: 2em auto; padding: 0 1em; }
    h1 { font-size: 1.2em; }
    table { border-collapse: collapse; width: 100%; }
    th, td { text-align: left; padding: 0.3em 0.5em; border-bottom: 1px solid #ccc; }
    td:nth-child(5) { font-size: 0.85em; }
    td:nth-child(5) details { white-space: pre-line; }
    td:nth-child(5) summary { cursor: pointer; }
    .slow { color: #c00; }
    .ok { color: #080; }
    a { color: inherit; }
    .header { display: flex; align-items: center; gap: 1em; }
    .gh-link { display: inline-flex; }
    .gh-link svg { width: 20px; height: 20px; }
    @media (prefers-color-scheme: dark) {
      body { background: #1a1a1a; color: #e0e0e0; }
      th, td { border-bottom-color: #444; }
      .slow { color: #ff6b6b; }
      .ok { color: #51cf66; }
    }
  </style>
</head>
<body>
  <div class="header">
    <h1>--help</h1>
    <a href="https://github.com/netanel-haber/dash-dash-help" class="gh-link" title="View on GitHub">
      <svg viewBox="0 0 16 16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg>
    </a>
  </div>
  <p>Let's help help help devs.</p>
  <p>Target: &lt;200ms. Most LLM CLI tools take 10+ seconds.</p>

  <table>
    <tr><th>command</th><th>library</th><th>time</th><th>version</th><th>install</th><th>pr</th></tr>
    <tr id="vllm"><td><code>./vllm_source/.venv/bin/vllm --help</code></td><td>VLLM</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667643088">0ms</a></td><td><a href="https://github.com/vllm-project/vllm/releases/tag/v0.13.0">0.13.0+cpu</a></td><td><details><summary><code>build from source</code></summary><code>sudo apt-get update -y
sudo apt-get install -y gcc-12 g++-12 libnuma-dev
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12
git clone --depth 1 --branch v0.13.0 https://github.com/vllm-project/vllm.git
cd vllm
uv venv
uv pip install cmake wheel packaging ninja "setuptools-scm>=8" numpy
uv pip install -r requirements/cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu
VLLM_TARGET_DEVICE=cpu uv pip install . --no-build-isolation --extra-index-url https://download.pytorch.org/whl/cpu</code></details></td><td>-</td></tr>
    <tr id="sglang"><td><code>.venv/bin/python -m sglang.launch_server --help</code></td><td>SGLang</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667603734">1ms</a></td><td><a href="https://github.com/sgl-project/sglang/releases/tag/v0.5.6.post3.dev728+gb7c7e03d9">0.5.6.post3.dev728+gb7c7e03d9</a></td><td><a href="https://docs.sglang.io/platforms/cpu_server.html">CPU install</a></td><td>-</td></tr>
    <tr id="ollama"><td><code>ollama --help</code></td><td>Ollama</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667542323">14ms</a></td><td><a href="https://github.com/ollama/ollama/releases/tag/v0.13.5">0.13.5</a></td><td><code>curl -fsSL https://ollama.com/install.sh | sh</code></td><td>-</td></tr>
    <tr id="llama.cpp"><td><code>./llama-bin/llama-cli --help</code></td><td>llama.cpp</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667713993">0ms</a></td><td><a href="https://github.com/ggml-org/llama.cpp/releases/tag/b7615">b7615</a></td><td><a href="https://github.com/ggml-org/llama.cpp/releases">pre-built binary</a></td><td>-</td></tr>
    <tr id="transformers"><td><code>.venv/bin/transformers-cli --help</code></td><td>Transformers</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667589551">1ms</a></td><td><a href="https://github.com/huggingface/transformers/releases/tag/v4.57.3">4.57.3</a></td><td><details><summary><code>uv pip install transformers torch</code></summary><code>uv venv
uv pip install transformers torch --extra-index-url https://download.pytorch.org/whl/cpu</code></details></td><td>-</td></tr>
    <tr id="hf"><td><code>.venv/bin/hf --help</code></td><td>Hugging Face Hub</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667566717">0ms</a></td><td><a href="https://github.com/huggingface/huggingface_hub/releases/tag/v1.2.3">1.2.3</a></td><td><code>uv pip install huggingface_hub</code></td><td>-</td></tr>
    <tr id="lm-eval"><td><code>.venv/bin/lm-eval --help</code></td><td>lm-eval</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667574707">0ms</a></td><td><a href="https://github.com/EleutherAI/lm-evaluation-harness/releases/tag/v0.4.9.2">0.4.9.2</a></td><td><code>uv pip install lm-eval</code></td><td>-</td></tr>
    <tr id="VLMEvalKit"><td><code>./VLMEvalKit/.venv/bin/python ./VLMEvalKit/run.py --help</code></td><td>VLMEvalKit</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667682674">0ms</a></td><td><a href="https://github.com/open-compass/VLMEvalKit/releases/tag/v0.1.0">0.1.0</a></td><td><details><summary><code>build from source</code></summary><code>git clone https://github.com/open-compass/VLMEvalKit.git
cd VLMEvalKit
uv venv
uv pip install -e .</code></details></td><td>-</td></tr>
    <tr id="tensorrt-llm"><td><code>.venv/bin/trtllm-serve --help 2&gt;/dev/null || true</code></td><td>TensorRT-LLM</td><td class="ok"><a href="https://github.com/netanel-haber/dash-dash-help/actions/runs/20667594479">0ms</a></td><td><a href="https://github.com/NVIDIA/TensorRT-LLM/releases/tag/v1.1.0">1.1.0</a></td><td><code>uv pip install tensorrt-llm</code></td><td>-</td></tr>
  </table>
</body>
</html>
